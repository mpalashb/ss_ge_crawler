# ss.ge Scrapy Spider

Getting each link and extracted particular data

![screenshot](screenshot/ss.ge-1.png)

Crawler going to each detail page and generating data, finally we exported into a CSV file!

![screenshot](screenshot/ss.ge-2.png)

### Requirements

> Have to install Scrapy

### Installation and Running

Once done your scrapy installation!

```
pip install openpyxl
git clone
cd ss_ge_v3
```

```
scrapy crawl ss -o out.csv
```

\*\* You can use any file name to replace out.csv
